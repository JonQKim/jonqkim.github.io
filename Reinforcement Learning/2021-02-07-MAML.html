
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <link rel="canonical" href="http://jonqkim.github.io/Reinforcement%20Learning/2021-02-07-MAML.html">
      
      
        <meta name="author" content="Jongkyu Kim">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-6.0.1">
    
    
      
        <title>Visualizing MAML with simple losses - Rage Against Deep Learning</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.38780c08.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.3f72e892.min.css">
        
      
    
    
    
      
        
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
    
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
      
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#quick-review-of-maml" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="http://jonqkim.github.io/" title="Rage Against Deep Learning" class="md-header-nav__button md-logo" aria-label="Rage Against Deep Learning">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            Rage Against Deep Learning
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              Visualizing MAML with simple losses
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="http://jonqkim.github.io/" title="Rage Against Deep Learning" class="md-nav__button md-logo" aria-label="Rage Against Deep Learning">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    Rage Against Deep Learning
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../index.html" title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      Deep Mind
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Deep Mind" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        <span class="md-nav__icon md-icon"></span>
        Deep Mind
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Deep%20Mind/2020-09-27-Understanding_Agent_Cooperation.html" title="Understanding Agent Cooperation - KR" class="md-nav__link">
      Understanding Agent Cooperation - KR
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Deep%20Mind/2020-11-10-Fast_reinforcmenet_learning_through_the_composition_of_behaviours.html" title="Fast reinforcement learning through the composition of behaviours - KR" class="md-nav__link">
      Fast reinforcement learning through the composition of behaviours - KR
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3" checked>
    
    <label class="md-nav__link" for="nav-3">
      Reinforcement Learning
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Reinforcement Learning" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        <span class="md-nav__icon md-icon"></span>
        Reinforcement Learning
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Visualizing MAML with simple losses
        <span class="md-nav__icon md-icon"></span>
      </label>
    
    <a href="2021-02-07-MAML.html" title="Visualizing MAML with simple losses" class="md-nav__link md-nav__link--active">
      Visualizing MAML with simple losses
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#quick-review-of-maml" class="md-nav__link">
    Quick review of MAML
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#case-1-simple" class="md-nav__link">
    Case 1: simple
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#case-2-slightly-more-complicated-at-first" class="md-nav__link">
    Case 2: slightly more complicated (at first)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#review" class="md-nav__link">
    Review
  </a>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#quick-review-of-maml" class="md-nav__link">
    Quick review of MAML
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#case-1-simple" class="md-nav__link">
    Case 1: simple
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#case-2-slightly-more-complicated-at-first" class="md-nav__link">
    Case 2: slightly more complicated (at first)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#review" class="md-nav__link">
    Review
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                  <h1>Visualizing MAML with simple losses</h1>
                
                <p>2021-02-07</p>
<hr />
<blockquote>
<p>The beauty of MAML is its simplicity.
The algorithm is very concise to be described just in a few lines.
Attracted to the beauty, in this article, I try to visualize what the algorithm does.
I hope it would help us get better understand of MAML.</p>
</blockquote>
<hr />
<h3 id="quick-review-of-maml">Quick review of MAML</h3>
<p>MAML algorithm is described as below.
It runs on a nested while loop.
Inner loop calculates task losses that are updated with gradient descent. 
And all task losses sum up to make meta objective loss. 
Then outer loop optimizes meta objective loss given by inner loop. </p>
<hr />
<p><strong>Algorithm: Model-Agnostic Meta-Learning</strong> </p>
<hr />
<p><strong>Require:</strong> <span class="arithmatex">\(p(T)\)</span>: distribution over tasks  <br>
<strong>Require:</strong> <span class="arithmatex">\(\alpha\)</span>, <span class="arithmatex">\(\beta\)</span>: step size hyperparameters <br>
<strong>Definition:</strong> <span class="arithmatex">\(L_{T_i}(f_\theta)\)</span>: Loss for a Task, <span class="arithmatex">\(T_i\)</span> <br>
<strong>Definition:</strong> <span class="arithmatex">\(\sum_{T_i \sim p(T)} L_{T_i}(f_{\theta_i^{'}})\)</span> : meta objective loss <br>
&emsp; 1: randomly initialize <span class="arithmatex">\(\theta\)</span> <br>
&emsp; 2: <strong>while</strong> not done <strong>do</strong> <br>
&emsp; 3: &emsp; Sample batch fo tasks <span class="arithmatex">\(T_i \sim p(T)\)</span> <br>
&emsp; 4: &emsp; <strong>for all</strong> <span class="arithmatex">\(T_i\)</span> <strong>do</strong> <br>
&emsp; 5: &emsp;&emsp; Evaluate <span class="arithmatex">\(\nabla_\theta L_{T_i}(f_\theta)\)</span> with respect to <span class="arithmatex">\(K\)</span> examples <br>
&emsp; 6: &emsp;&emsp; Compute adapted parameters with gradient decent: <span class="arithmatex">\(\theta_i^{'} = \theta - \alpha \nabla_\theta L_{T_i}(f_\theta)\)</span> <br>
&emsp; 7: &emsp; <strong>end for</strong> <br>
&emsp; 8: &emsp; Update meta objective with gradient descent: <span class="arithmatex">\(\theta \leftarrow \theta - \beta \nabla_\theta \sum_{T_i \sim p(T)} L_{T_i}(f_{\theta_i^{'}})\)</span> </p>
<hr />
<p>Let me show two cases that are very simple but still valid for meta learning set-up shown above.
For each case, I will visualize task losses and the corresponding meta objective loss.</p>
<h3 id="case-1-simple">Case 1: simple</h3>
<p>Let's assume we have two tasks <span class="arithmatex">\(T_0\)</span> and <span class="arithmatex">\(T_1\)</span>.
Then we set very simple loss functions for the two tasks as below.</p>
<p><span class="arithmatex">\(L_{T_0} = \frac{1}{2} \theta^2 \\\)</span> <br>
<span class="arithmatex">\(L_{T_1} = \frac{1}{2} (\theta - 1)^2\)</span></p>
<p>The two equations have the same shape and the only difference is shift by 1 in <span class="arithmatex">\(\theta\)</span> axis.
Their visualization are as below.</p>
<iframe width="640" height="640" frameborder="0" scrolling="no" src="//plotly.com/~jonqkim/134.embed"></iframe>

<p>We update the parameters, <span class="arithmatex">\(\theta_{0}\)</span> and <span class="arithmatex">\(\theta_{1}\)</span> with gradient descent using pre-defined learning rate, <span class="arithmatex">\(\alpha\)</span>.</p>
<div class="arithmatex">\[\begin{equation}
\begin{split}
\theta^{'}_{0} &amp;= \theta - \alpha \nabla_{\theta} L_{T_0}(f_{\theta}) = \theta - \alpha \theta \\
&amp;= (1 - \alpha) \theta\\
\theta^{'}_1 &amp;= \theta - \alpha \nabla_{\theta} L_{T_1}(f_{\theta}) = \theta - \alpha (\theta - 1)\\
&amp;= (1 - \alpha) \theta + \alpha
\end{split}
\end{equation}\]</div>
<p>We update the loss functions using the updated <span class="arithmatex">\(\theta\)</span> parameters.
$$ \begin{equation}
\begin{split}
L_{T_0} &amp;= \frac{1}{2} (1-\alpha)^2\theta^2 \
L_{T_1} &amp;= \frac{1}{2} (1-\alpha)^2(\theta-1)^2
\end{split}
\end{equation}$$</p>
<p>Finally, we sum up the updated losses to get the loss for meta-objective.
Remeber that the goal of meta-learning is to find a <span class="arithmatex">\(\theta\)</span> that minimizes the meta-objective loss.
$$ \begin{equation}
\begin{split}
L_{M} &amp;= \frac{1}{2} (1-\alpha)^2 { \theta^2 + (\theta-1)^2 } \
&amp;= (1-\alpha)^2 { (\theta-\frac{1}{2})^2 + \frac{1}{4} }
\end{split}
\end{equation}$$</p>
<p>From the equation, <span class="arithmatex">\(\alpha\)</span> scales the graph in <span class="arithmatex">\(y\)</span> axis but does not alter the scale or position in <span class="arithmatex">\(x\)</span> axis.
The graph of the equation given <span class="arithmatex">\(\alpha = 0.5\)</span> is shown below.</p>
<p><iframe
    width="480px"
    height="480px"
    src="https://plotly.com/~jonqkim/136.embed"
    frameborder="0"
    allowfullscreen></iframe></p>
<p>Becasue we set simple task loss functions, the meta-objective loss function is also very simple. 
We easily find the optimal <span class="arithmatex">\(\theta\)</span> to be 0.5 even regardless of <span class="arithmatex">\(\alpha\)</span> in this case. 
And the optimal <span class="arithmatex">\(\theta\)</span> is intuitively understood because we have two loss functions of an identical shape and the middle point in <span class="arithmatex">\(\theta\)</span> axis is 0.5.</p>
<p>Just one more thing to notice is when <span class="arithmatex">\(\alpha\)</span> gets close to <span class="arithmatex">\(1\)</span> where <span class="arithmatex">\(L_M\)</span> becomes <span class="arithmatex">\(0\)</span> for any <span class="arithmatex">\(\theta\)</span>. 
As <span class="arithmatex">\(\alpha\)</span> gets close to 1, gradient descent with respect to <span class="arithmatex">\(\theta\)</span> gets smaller and finally becomes <span class="arithmatex">\(0\)</span> at <span class="arithmatex">\(alpha = 1\)</span> over all <span class="arithmatex">\(\theta\)</span>. 
Actually, it is the best <span class="arithmatex">\(\alpha\)</span> that we can choose because it makes both task losses <span class="arithmatex">\(0\)</span> after gradient descent update.</p>
<p>The process of calculation was interesting but the result turns out somewhat trivia. 
It seems like that's it for what we can get from it. 
So now we set a slightly more complicated task loss function.</p>
<h3 id="case-2-slightly-more-complicated-at-first">Case 2: slightly more complicated (at first)</h3>
<p>Now we change <span class="arithmatex">\(L_{T_0}\)</span> from quadratic to quartic function.</p>
<p><span class="arithmatex">\(L_{T_0} = \frac{1}{4} \theta^4\)</span> <br><span class="arithmatex">\(L_{T_1} = \frac{1}{2} (\theta - 1)^2\)</span></p>
<p>Below are their visualization in graph.</p>
<p><iframe
    width="480px"
    height="640px"
    src="https://plotly.com/~jonqkim/138.embed"
    frameborder="0"
    allowfullscreen></iframe></p>
<p>We do the same steps as in case 1.
The updated parameters <span class="arithmatex">\(\theta'_{0}\)</span> and <span class="arithmatex">\(\theta'_{1}\)</span> are as below.
(<span class="arithmatex">\(\theta^{'}_1\)</span> did not change from case 1 but was written again for easier track of calculation.)
$$ \begin{equation}
\begin{split}
\theta^{'}<em>0  &amp;= \theta - \alpha \nabla</em>{\theta} L_{T_0}(f_{\theta})\
 &amp;= \theta - \alpha \theta^3 \
\theta^{'}<em>1  &amp;= \theta - \alpha \nabla</em>{\theta} L_{T_1}(f_{\theta})\
 &amp;= \theta - \alpha (\theta - 1) \
 &amp;= (1 - \alpha) \theta + \alpha \
\end{split}
\end{equation}$$</p>
<p>Then, we update the task loss functions by replacing <span class="arithmatex">\(\theta\)</span> with the updated <span class="arithmatex">\(\theta'_{0}\)</span> and <span class="arithmatex">\(\theta'_{1}\)</span>.
$$ \begin{equation}
\begin{split}
L_{T_0} &amp;= \frac{1}{4} (\theta - \alpha \theta^3)^4 \
L_{T_1} &amp;= \frac{1}{2} (1-\alpha)^2(\theta-1)^2
\end{split}
\end{equation} $$</p>
<p>The two updated task losses sum up to meta-objective loss as below.
The equation looks still simple but now it is hard to imagine the graph.
$$ \begin{equation}
\begin{split}
L_{M} &amp;= \frac{1}{4} (\theta - \alpha \theta^3)^4 \
&amp;+ \frac{1}{2} (1-\alpha)^2(\theta-1)^2
\end{split}
\end{equation} $$</p>
<p>So let us visualize the equation in a graph.
This time, <span class="arithmatex">\(\alpha\)</span> is involved not in a simple manner.
So we need to include <span class="arithmatex">\(\alpha\)</span> as another axis and draw the loss not as a line but as a surface.
(In the fiture below, you can hover your mouse pointer over the surface to see graphs drawn by fixing <span class="arithmatex">\(\theta\)</span> or <span class="arithmatex">\(\alpha\)</span>.)</p>
<p><iframe
    width="640px"
    height="640px"
    src="https://plotly.com/~jonqkim/166.embed"
    frameborder="0"
    allowfullscreen></iframe></p>
<p>Now we found the graph is not simple that it is not easy to find the optimal <span class="arithmatex">\(\theta\)</span> that makes the loss minimum.
In order to find the <span class="arithmatex">\(\theta\)</span>, let us draw the gradient of meta-object loss over <span class="arithmatex">\(\theta\)</span> shown as below.</p>
<p><span class="arithmatex">\(\nabla_{\theta} L_{M} = (\theta - \alpha \theta^3)^3(1 - 3 \alpha \theta^2) + (1-\alpha)^2(\theta-1)\)</span></p>
<p>Below is the surface visualization of the equation above. 
The intersection of the surface and the transprant plane where <span class="arithmatex">\(z=0\)</span> makes curvese that make the meta-objective loss minimum. 
We can see the optimal <span class="arithmatex">\(\theta\)</span> easier than in the previous visualization. 
And we see strong dependency of the optimal <span class="arithmatex">\(\theta\)</span> on <span class="arithmatex">\(\alpha\)</span>. </p>
<p>In case 2, we changed just one task loss function from <span class="arithmatex">\(\theta^2\)</span> to <span class="arithmatex">\(\theta^4\)</span>. 
But we see meta-objective loss surface that is much more complicated both over <span class="arithmatex">\(\theta\)</span> and <span class="arithmatex">\(\alpha\)</span>.</p>
<p><iframe
    width="640px"
    height="640px"
    src="https://plotly.com/~jonqkim/164.embed"
    frameborder="0"
    allowfullscreen></iframe></p>
<h3 id="review">Review</h3>
<p>We saw what MAML actually does via simple loss functions and their visualizations. </p>
<p>From the visualization, I would like to point out two things. 
First, the process and the resulting performance largely affected by task learning rate, <span class="arithmatex">\(\alpha\)</span>. 
Second, even rather simple task loss functions can lead to complicated meta-objective function. </p>
<p>I hope you enjoed it and got more concrete understanding about MAML.</p>
                
                  
                
              
              
                

  


  <h2 id="__comments">Comments</h2>
  <div id="disqus_thread"></div>
  <script>var disqus_config=function(){this.page.url="http://jonqkim.github.io/Reinforcement%20Learning/2021-02-07-MAML.html",this.page.identifier="Reinforcement%20Learning/2021-02-07-MAML.html"};window.addEventListener("load",function(){var e=document,i=e.createElement("script");i.src="//jongkyu-kim.disqus.com/embed.js",i.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(i)})</script>

              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../Deep%20Mind/2020-11-10-Fast_reinforcmenet_learning_through_the_composition_of_behaviours.html" title="Fast reinforcement learning through the composition of behaviours - KR" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Fast reinforcement learning through the composition of behaviours - KR
              </div>
            </div>
          </a>
        
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/vendor.77e55a48.min.js"></script>
      <script src="../assets/javascripts/bundle.aa3f9871.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}</script>
      
      <script>
        app = initialize({
          base: "..",
          features: [],
          search: Object.assign({
            worker: "../assets/javascripts/worker/search.4ac00218.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="../javascripts/config.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>